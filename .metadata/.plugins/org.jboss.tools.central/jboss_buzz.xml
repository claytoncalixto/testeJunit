<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Join the Red Hat team at OpenJS World 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/a2xNf6CngUk/join-red-hat-team-openjs-world-2021" /><author><name>Michael Dawson</name></author><id>066f25a4-7a0e-43d1-be62-1bfd9f4ef265</id><updated>2021-06-01T12:30:00Z</updated><published>2021-06-01T12:30:00Z</published><summary type="html">&lt;p&gt;Red Hat is excited to be back at the &lt;a href="https://openjsf.org/openjs-world-2021/"&gt;OpenJS World&lt;/a&gt; conference again this year. We look forward to connecting with you to explore the impact &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; are having on technologies of all kinds, especially in the area of cloud-native development.&lt;/p&gt; &lt;p&gt;Many developers and community contributors from the Red Hat and IBM teams will deliver talks and participate in conference events. We hope to see you there!&lt;/p&gt; &lt;h2&gt;OpenJS World keynotes, sessions, and labs hosted by Red Hat and IBM&lt;/h2&gt; &lt;p&gt;This year's virtual event includes many great topics and speakers.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Keynotes:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Wednesday, June 2 at 9:00 a.m. PDT: &lt;a href="https://openjsworld2021.sched.com/event/j00p/welcome-keynote-the-roaring-twenties-for-javascript-robin-bender-ginn-executive-director-openjs-foundation-todd-moore-vp-of-open-technology-and-developer-advocacy-ibm"&gt;The Roaring Twenties for JavaScript&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Co-presented by Todd Moore (Vice President, Open Technology and Developer Advocacy, IBM)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Wednesday, June 2 at 10:25 a.m. PDT: &lt;a href="https://openjsworld2021.sched.com/event/j06C/keynote-open-open-source-and-making-great-places-for-collaboration-joe-sepi-open-source-engineer-advcoate-ibm-michael-dawson-nodejs-lead-for-ibm-and-red-hat-beth-griggs-senior-software-engineer-red-hat"&gt;Open Open Source and Making Great Places for Collaboration&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Joe Sepi (Open Source Engineer &amp; Advocate, IBM), Michael Dawson (Node.js lead, IBM and Red Hat), and Bethany Griggs (Senior Software Engineer, Red Hat)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Sessions:&lt;/strong&gt; Available together June 2 at 1:00 p.m. PDT.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/izzz/internet-of-things-iot-with-node-both-practical-and-fun-jesse-gorzinski-ibm-michael-dawson-red-hat"&gt;Internet of Things (IoT) with Node: Both Practical and Fun!&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Jesse Gorzinski (IBM) and Michael Dawson (Red Hat)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/j002/nodejs-diagnostic-best-practices-gireesh-punathil-ibm-india-mary-marchini-netflix"&gt;Node.js Diagnostic Best Practices&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Co-presented by Gireesh Punathil (IBM India)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/izze/panel-nodejs-package-maintenance-working-group-year-3-glenn-hinks-american-express-bethany-griggs-red-hat-darcy-clarke-github-dominykas-blyze-nearform-rodion-abdurakhimov-aspire-global"&gt;Node.js Package Maintenance Working Group: Year 3&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Panel discussion featuring Bethany Griggs (Red Hat)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/j06f/responsible-coding-for-a-better-future-lucile-jerber-stephane-rodet-ibm"&gt;Responsible Coding for a Better Future&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Lucile Jerber and Stephane Rodet (IBM)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/j00K/take-a-trip-through-jslandia-joe-sepi-ibm-jory-burson-linux-foundation"&gt;Take a Trip through JSLandia&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Co-presented by Joe Sepi (IBM)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/j005/application-modernization-with-camel-javascript-and-openshift-ip-sam-wuxin-zeng-red-hat"&gt;Application Modernization with Camel JavaScript and OpenShift&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Ip Sam and Wuxin Zeng (Red Hat)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/izzt/nodejs-deep-debugging-gireesh-punathil-ibm-india"&gt;Node.js Deep Debugging&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Gireesh Punathil (IBM India)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/izzD/nodejs-the-new-and-the-experimental-bethany-griggs-red-hat"&gt;Node.js: The New and the Experimental&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Bethany Griggs (Red Hat)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://openjsworld2021.sched.com/event/izyR/cloud-native-landscape-for-nodejs-developers-upkar-lidder-ibm"&gt;Cloud Native Landscape for Node.js Developers&lt;/a&gt; &lt;ul&gt;&lt;li&gt;Presented by Upkar Lidder (IBM)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;We are also hosting a set of labs on June 3. For more information, check out &lt;a href="https://developer.ibm.com/conferences/openjs-world/"&gt;OpenJS World: IBM Day of Workshops&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Explore more Node.js resources&lt;/h2&gt; &lt;p&gt;If you want to learn more about Red Hat and IBM’s involvement in the Node.js community and what we are working on, check out our topic pages at &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Red Hat Developer&lt;/a&gt; and &lt;a href="https://developer.ibm.com/languages/node-js/"&gt;IBM Developer&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/06/01/join-red-hat-team-openjs-world-2021" title="Join the Red Hat team at OpenJS World 2021"&gt;Join the Red Hat team at OpenJS World 2021&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/a2xNf6CngUk" height="1" width="1" alt=""/&gt;</summary><dc:creator>Michael Dawson</dc:creator><dc:date>2021-06-01T12:30:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/06/01/join-red-hat-team-openjs-world-2021</feedburner:origLink></entry><entry><title>How to create a better front-end developer experience</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lVMpKj-n8rc/how-create-better-front-end-developer-experience" /><author><name>Zackary Allen</name></author><id>9a17ebc5-2eca-4ea4-bdeb-3443661d9df2</id><updated>2021-06-01T07:00:00Z</updated><published>2021-06-01T07:00:00Z</published><summary type="html">&lt;p&gt;Who are the first users of a new feature or new application? If you think they are customers, think again.&lt;/p&gt; &lt;p&gt;The first users are actually the front-end developers, and their experience testing those new applications and features makes your first &lt;a href="https://developers.redhat.com/blog/category/uiux/"&gt;user experience&lt;/a&gt; (UX). If your front-end developers have a smooth experience developing new products, your users will almost always have a smooth experience using them.&lt;/p&gt; &lt;p&gt;Take developing a form using React, for example. If developers are able to develop the form without any difficulty, it will likely be a positive experience for the customer as well. The reason? The developer had to fill out the form to test it. If tweaking the form takes one second but filling it out takes one minute, the developer will probably find a way to reduce the feedback loop. It might be reduced through technical means by integrating with browsers that autofill address fields, or by advising the design team that the form could be split up so it can be more modularly tweaked and tested. Whatever the case, &lt;em&gt;developers tend to write software consistent with their tools&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;That's why UX design teams should strive to not only improve the end-user experience in their products, but also streamline the experience of the developers who build them. &lt;em&gt;Developer experience&lt;/em&gt; refers to the workflow developers move through as they write, update, and maintain code for each release. From local build tooling to shared workflows and shared deployments, strong developer experience paves the path for solid UX.&lt;/p&gt; &lt;p&gt;In this article, we'll explore common pain points that can complicate the development process and how to address them to foster better developer experiences.&lt;/p&gt; &lt;h2&gt;What makes a good developer experience?&lt;/h2&gt; &lt;p&gt;Front-end developers want to be able to write code to add features in an environment that closely resembles what users will encounter in the end product. After committing and pushing their code changes, they'd typically like to run tests to make sure their changes don't break anything unexpectedly. Beyond test validation, front-end developers might want to validate new features by sharing a link with stakeholders. Once their changes meet the stakeholders' criteria, developers want their code to make its way into the central repository and then to end users. Sometimes the new features reach end users as soon as the changes are merged, and sometimes that transition happens on a time-based schedule.&lt;/p&gt; &lt;p&gt;A strong front-end developer experience moves smoothly through each of these phases. Unfortunately, few front-end development experiences are seamless.&lt;/p&gt; &lt;h2&gt;Common pain points for front-end developers&lt;/h2&gt; &lt;p&gt;Common front-end development pain points span three main areas: environments, testing, and releases. Often, front-end development environments lack key features that end-user environments have, such as authorization or live data. Frequently, networking pieces are missing or need to be properly proxied to test these environments. And speaking of tests, they don't write, run, or analyze themselves!&lt;/p&gt; &lt;p&gt;There's no silver bullet that solves any of these problems, yet front-end developers spend a significant portion of their time on them. Let's examine each of these pain points in detail, and look at methods front-end developers and &lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; engineers can use to help solve them.&lt;/p&gt; &lt;h3&gt;Pain point #1: Environments&lt;/h3&gt; &lt;p&gt;While most front ends start standalone, few continue on their own because they usually need certain back-end services. Back-end developers can develop without a front end, but front-end developers certainly can’t develop without a back end. In general, there are three solutions to running back-end services to use against a local front end:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Run the back-end services locally (see Figure 1).&lt;/li&gt; &lt;li&gt;Use a shared back-end deployment.&lt;/li&gt; &lt;li&gt;Use mock data in your front end.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Solutions one and three allow offline development. While an internet connection is a given nowadays, offline development is still a better experience than online development for developers who travel or live in places that experience intermittent outages due to weather. Offline development also doesn't require a VPN, which can be difficult to set up on certain devices.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/hot-reloading.gif"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/hot-reloading.gif" width="2607" height="1387" alt="Text editor and browser open side-by-side" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Hot-reloading changes with Webpack on a local cloud.redhat.com environment with back-end services running locally.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Solutions one and two require an extra step to run a command before developing the front end. The local back end might need additional configuration (like a database), and a shared back end might require a proxy. This leads to a worse developer experience but can help catch back-end bugs earlier than mocking the data might.&lt;/p&gt; &lt;p&gt;The third solution provides the best overall developer experience but requires the most work, because each back-end endpoint must be spoofed to return mocked data. This requires front-end and back-end developers working together to create mocks.&lt;/p&gt; &lt;p&gt;The first solution provides the best back-end developer experience because they can test local back-end changes against a front end.&lt;/p&gt; &lt;p&gt;The environment is the first pain point that needs solving for front-end developers, and is generally the hardest of the common pain points to get right. Being able to work offline is a good experience. Not having to run a back end to make front end changes is a &lt;em&gt;great&lt;/em&gt; experience.&lt;/p&gt; &lt;h3&gt;Pain point #2: Testing&lt;/h3&gt; &lt;p&gt;Most front ends don't start out needing tests. However, as they grow, it's important that the user experience doesn't degrade when adding new features or fixing unrelated bugs. Writing, running, and reporting tests can be painful. Let's take a look at how to ease the testing process across two different front-end testing categories: unit tests and integration tests.&lt;/p&gt; &lt;h4&gt;Unit tests&lt;/h4&gt; &lt;p&gt;The best way to make test writing easier is only to write tests that are important. Adding automatic snapshot tests for custom components can help catch bugs. After that, spend time testing event and state interactions. When developing tests, most tools have a watch mode that can be used to run tests only when the test files change.&lt;/p&gt; &lt;h4&gt;Integration tests&lt;/h4&gt; &lt;p&gt;With certain frameworks, it’s possible to &lt;a href="https://chrome.google.com/webstore/detail/cypress-recorder/glcapdcacdfkokcmicllhcjigeodacab?hl=en-US"&gt;record user interactions&lt;/a&gt; on a webpage to avoid coding the test cases yourself. For large test suites, tools like &lt;a href="https://www.browserstack.com/"&gt;BrowserStack&lt;/a&gt; offer a grid of 10 concurrent runners for free and open source accounts.&lt;/p&gt; &lt;h4&gt;Reporting tests&lt;/h4&gt; &lt;p&gt;There are dozens of reporting formats, but HTML reports that can be uploaded to a pull request (PR) like the &lt;a href="https://github.com/patternfly/patternfly-react/pull/5524"&gt;one shown in Figure 2&lt;/a&gt; are usually best. For unit tests, tools like &lt;a href="http://codecov.io"&gt;Codecov&lt;/a&gt; can help maintain a certain coverage percentage as well.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/a11y-report.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/a11y-report.png?itok=4Rc7RPoX" width="600" height="345" alt="An HTML accessibility report for an @patternfly/react-core pull request " typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: An HTML accessibility report for a pull request complete with screenshots.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Pain point #3: Releasing&lt;/h3&gt; &lt;p&gt;When opening a pull request, it’s often useful to share changes with designers and other developers in the form of a PR preview. If you just need to host static files, services like &lt;a href="https://www.netlify.com/"&gt;Netlify&lt;/a&gt; can work with minimal configuration, or a service like &lt;a href="https://surge.sh/"&gt;Surge&lt;/a&gt; can work with an existing continuous integration (CI) system. For sites that also need a back end, &lt;a href="https://vercel.com/"&gt;Vercel&lt;/a&gt; and &lt;a href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt; have free tiers sufficient for most deployments.&lt;/p&gt; &lt;p&gt;For releasing, tools like &lt;a href="https://github.com/semantic-release/semantic-release"&gt;semantic-release&lt;/a&gt; for normal repos and &lt;a href="https://lerna.js.org/"&gt;Lerna&lt;/a&gt; for monorepos (see Figure 3) can release to Git, GitHub, or Node Package Manager (npm) on every push to the main branch of your repository. Of course, there's always the option to write your own bash script for complete flexibility.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/patternfly-npm.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/patternfly-npm.png?itok=qIk-spJt" width="600" height="294" alt="Lerna auto-releasing @patternfly/react-* packages to npm from a merged pull request." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Lerna auto-releasing @patternfly/react-* packages to npm from a merged pull request.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion: Developer experience is user experience&lt;/h2&gt; &lt;p&gt;Improving the front-end developer experience lowers the cost of front-end development and enhances the overall user experience. Addressing front-end developer pain points will look different for every project, but the payoff is the same: A smoother experience for developers carries through to your end users.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/06/01/how-create-better-front-end-developer-experience" title="How to create a better front-end developer experience "&gt;How to create a better front-end developer experience &lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lVMpKj-n8rc" height="1" width="1" alt=""/&gt;</summary><dc:creator>Zackary Allen</dc:creator><dc:date>2021-06-01T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/06/01/how-create-better-front-end-developer-experience</feedburner:origLink></entry><entry><title type="html">Retail data framework - Common architectural elements</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/xXFiSsZFv0A/retail-data-framework-common-architectural-elements.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/zejVwlU1WVc/retail-data-framework-common-architectural-elements.html</id><updated>2021-06-01T05:00:00Z</updated><content type="html">Part 2 - Common architectural elements  In our  from this series we introduced a use case around the data framework for retail stores. The process was laid out how we've approached the use case and how portfolio solutions are the base for researching a generic architectural blueprint.  The only thing left to cover was the order in which you'll be led through the blueprint details. This article starts the real journey at the very top, with a generic architecture from which we'll discuss the common architectural elements one by one. This will start our journey into the logical elements that make up the real-time stock control architecture blueprint. BLUEPRINTS REVIEW As mentioned before, the architectural details covered here are base on real solutions using open source technologies. The example scenario presented here is a generic common blueprint that was uncovered researching those solutions. It's our intent to provide a blueprint that provides guidance and not deep technical details. This section covers the visual representations as presented, but it's expected that they'll be evolving based on future research. There are many ways to represent each element in this architectural blueprint, but we've chosen a format that we hope makes it easy to absorb. Feel free to post comments at the bottom of this post, or  with your feedback. FROM SPECIFIC TO GENERIC Before diving in to the common elements, it might be nice to understand that this is not a catch all for every possible supply chain integration solution. It's a collection of identified elements that we've uncovered in multiple customer implementations. These elements presented here are then the generic common architectural elements that we've identified and collected in to the generic architectural blueprint.  It's our intent to provide a blueprint for guidance and not deep technical details. You're smart enough to figure out wiring integration points in your own architectures. You're capable of slotting in the technologies and components you've committed to in the past where applicable.  It's our job here to describe the architectural blueprint generic components and outline a few specific cases with visual diagrams so that you're able to make the right decisions from the start of your own projects. Another challenge has been how to visually represent the architectural blueprint. There are many ways to represent each element, but we've chosen some icons, text and colours that we hope are going to make it all easy to absorb. Now let's take a quick tour of the generic architecture and outline the common elements uncovered in my research. DATA INTEGRATION PLATFORM The logical view splits this solution space into several identifiable platforms where the retail data framework is managed. It takes all three of these platforms to ensure that the data is collected, integrated with the various blueprints external to the framework, processed, validated, stored, data science is applied for insights, and exposed back out to the entire retail organisation. The first we'll look at is the data integration platform where the main action takes place with the retail data framework. Here there are integration microservices and data integration microservices to provide integration with the core platform, data science platform, and storage services.  Another important set of elements found in this platform are messaging and event processing. Both are essential elements to ensure microservice communications and message transformation within the architecture. To help with data performance, availability, and management there are data caching microservices and data virtualisation microservices.  Next up, process automation is used to capture processes within the retail organisation, manage the processing and validation of data in a structured traceable manner. The business automation microservices capture all of these processes and ensure proper monitoring of the compliance and regulatory rules for the entire retail organisation.  Finally, ensuring that the fronting web applications have good visual data representations requires that all microservices are only accessed by authenticated and authorised parties. This is taken care of through the use of an API management element.  You can sense that this data integration platform contains the elements focusing on microservice deployments which lend themselves to a cloud-native development process using containers and container platforms.  CORE PLATFORM A core platform focusing on security and compliance requires the hosting of retail organisation wide tooling. These are not specifically called out and can be any number of core services or systems hosted within the retail organisation or outside in the form of Software as a Service (SaaS) solutions. This platform hosts a set of four elements that each support the organisation, starting with compliance and regulatory tooling. This is not the rules mentioned in the previous section, but the tooling backing the development, deployment, and maintenance of the compliance and regulatory rules.  There should be some form of auditing tooling and governance tooling used to ensure data and the services used to support the retail data framework are properly monitored in their application. Finally, the authentication and authorisation tooling is the central system used to plug in organisational wide access to the right parties within the retail data framework. DATA SCIENCE PLATFORM Any retail organisation working in their markets has a vast interest in the behaviour patterns of their customers. At the very least they are using the most basic data science elements, and in advanced cases, they are leveraging all forms of data science to advance their market positions. In the data science platform we find the more classical business intelligence tooling, often an externally hosted system noted here with a private cloud icon. Providing views and cuts of the mass data collected in retail organisations is the fundamental function of this element.  The advanced use of not just analytics on their data, but applying more sophisticated technologies like data science (AI / ML) allows retail organisations to gain advantageous insights into customers, trends, products, sales, and other retail activities that raw data analysis can't provide. Finally, there is data visualisation tooling that provides clear visibility to the consumers of the data and analysis generated from the other elements on this platform. STORAGE SERVICES The storage services uncovered in this solution space was a fairly diverse and more high level than the usually noted storage elements found in our architecture blueprints. As these storage needs are data focused and organisation wide solutions, you find all the major technologies in the data world applied here, such as data lakes, data warehousing, data hubs, and data marts. WHAT'S NEXT This was just a short overview of the common generic elements that make up our architecture blueprint for the retail data framework use case.  An overview of this series on retail data framework portfolio architecture blueprint: 1. 2. 3. Example data architecture Catch up on any past articles you missed by following any published links above. Next in this series, taking a look at an example data framework architecture for this blueprint. (Article co-authored by , Chief Architect Retail, Red Hat)&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/xXFiSsZFv0A" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/zejVwlU1WVc/retail-data-framework-common-architectural-elements.html</feedburner:origLink></entry><entry><title type="html">Eclipse Vert.x 4.1.0 released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-N-Iek-NXNQ/eclipse-vert-x-4-1-0" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-4-1-0</id><updated>2021-06-01T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.1.0 has just been released. It comes with a set of new exciting features!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-N-Iek-NXNQ" height="1" width="1" alt=""/&gt;</content><dc:creator>Julien Viet</dc:creator><feedburner:origLink>https://vertx.io/blog/eclipse-vert-x-4-1-0</feedburner:origLink></entry><entry><title type="html">Infinispan (Red Hat Data Grid) featured in Red Hat Developers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lF7ai7DIYvI/infinispan-redhat-summit-quarkus" /><author><name>Katia Aresti</name></author><id>https://infinispan.org/blog/2021/05/31/infinispan-redhat-summit-quarkus</id><updated>2021-05-31T12:00:00Z</updated><content type="html">Dear Infinispan Community, The Infinispan team is pleased to share an article published over on the Red Hat Developer blog. Part one of a two-part series of articles, this blog post focuses on how Data Grid, which is built on Infinispan, was used to create a leaderboard for an online Battleship game that featured at this year’s Red Hat Summit Keynote. You can read the blog post Technologies featured in our keynote demo: * Quarkus and Infinispan Client Extension * Additional Quarkus extensions: RestEasy, Websockets, Scheduler * Infinispan Query * Infinispan Cross-Site Replication * Infinispan Kubernetes Operator Enjoy your reading!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lF7ai7DIYvI" height="1" width="1" alt=""/&gt;</content><dc:creator>Katia Aresti</dc:creator><feedburner:origLink>https://infinispan.org/blog/2021/05/31/infinispan-redhat-summit-quarkus</feedburner:origLink></entry><entry><title>Learn Quarkus faster with quick starts in the Developer Sandbox for Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FSoQUzD7WPk/learn-quarkus-faster-quick-starts-developer-sandbox-red-hat-openshift" /><author><name>Daniel Oh</name></author><id>9e2c023a-1daf-4ba7-b00d-1bf2469de902</id><updated>2021-05-31T07:00:00Z</updated><published>2021-05-31T07:00:00Z</published><summary type="html">&lt;p&gt;Java developers are usually required to take many actions before we can begin developing and deploying cloud-native &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. First, we have to configure everything from the integrated development environment (IDE) to build tools such as &lt;a href="https://maven.apache.org"&gt;Maven&lt;/a&gt; or &lt;a href="https://gradle.org"&gt;Gradle&lt;/a&gt;. We also need to configure the command-line tools used for containerization and generating the Kubernetes manifest. If we don’t want to spin up a Kubernetes cluster locally, we also must connect to a remote Kubernetes cluster for continuous testing and deployment.&lt;/p&gt; &lt;p&gt;Developers should spend less time on configuration and more time accelerating the inner-loop development cycle of building, testing, and deploying our applications. Ideally, we should be able to continuously develop applications in a pre-configured Kubernetes environment.&lt;/p&gt; &lt;p&gt;This article is a guide to configuring Java applications using &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; quick starts in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;. As you'll see, using quick starts in the developer sandbox lets you focus on the inner loop of development, without needing to configure the Kubernetes cluster or development tools.&lt;/p&gt; &lt;p&gt;Developers using the developer sandbox have access to a shared, multi-tenant &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift 4&lt;/a&gt; cluster with a set of pre-installed developer tools such as a web-based IDE and &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt;. You can get started in less than five minutes with a free Red Hat developer account. To learn more about the developer sandbox, click &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Step 1: Launch your developer sandbox&lt;/h2&gt; &lt;p&gt;Assuming you have set up and signed into your Red Hat developer account, you can start your OpenShift environment in the developer sandbox. Go to the &lt;a href="https://developers.redhat.com/developer-sandbox/get-started"&gt;Get started in the Sandbox&lt;/a&gt; page, then click on &lt;strong&gt;Start using your Sandbox&lt;/strong&gt;, as shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The 'Get started in the Sandbox' option is selected." data-entity-type="file" data-entity-uuid="b962a4e4-1ead-4fb6-a35c-4dbab2a3f534" height="380" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.21.07%20PM.png" width="593" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 1: Start using your developer sandbox.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: You must choose &lt;strong&gt;DevSandbox&lt;/strong&gt; to log into the cluster.&lt;/p&gt; &lt;h2&gt;Step 2: Explore Quarkus quick starts&lt;/h2&gt; &lt;p&gt;Once you log in, you will arrive at the OpenShift topology view. Click &lt;strong&gt;View all Quick Starts&lt;/strong&gt; then enter a search for "Quarkus." You will see the three quick starts shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Enter a search for 'Quarkus' to view the three available Quarkus quick starts." data-entity-type="file" data-entity-uuid="765f40f4-ee54-4177-a1b0-8453ba53c653" height="197" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.22.49%20PM.png" width="586" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2: Quarkus quick starts in the OpenShift topology view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Step 3: Open your first Quarkus quick start&lt;/h2&gt; &lt;p&gt;Select the "Get started with Quarkus using S2I" quick start shown in Figure 2. This 10-minute quick start takes you through the six tasks to create and deploy a Quarkus application on OpenShift using a source-to-image (S2I) approach:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Create the Quarkus application.&lt;/li&gt; &lt;li&gt;View the build status.&lt;/li&gt; &lt;li&gt;View the associated Git repository.&lt;/li&gt; &lt;li&gt;View the pod status.&lt;/li&gt; &lt;li&gt;Change the deployment icon to Quarkus.&lt;/li&gt; &lt;li&gt;Run the Quarkus application.&lt;/li&gt; &lt;/ol&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The Quarkus project is automatically created for you in the sandbox environment, so you can skip the first task and complete the quick start faster.&lt;/p&gt; &lt;h2&gt;Step 4: Run the 'Get started with Quarkus using S2I' quick start&lt;/h2&gt; &lt;p&gt;When you are ready, click &lt;strong&gt;Start tour&lt;/strong&gt;, as shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The six tasks are shown, along with the option to start the tour." data-entity-type="file" data-entity-uuid="66c5f6e0-cc7b-499d-ae69-7ab23292c9db" height="424" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.24.16%20PM_1.png" width="456" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 3: Start the tour.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The tour guides you through the step-by-step instructions to complete the tasks in this quick start. You can skip the first task because it has already been done automatically for you, as shown in Figure 4.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The project has already been created automatically." data-entity-type="file" data-entity-uuid="b67d70e4-fa40-4bc5-8b76-1eb007e04ea0" height="347" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.25.30%20PM.png" width="588" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 4: The Quarkus application has already been created.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When you complete each step, click &lt;strong&gt;Next&lt;/strong&gt; to verify your work. If you have accomplished the task without any issues, click &lt;strong&gt;Yes&lt;/strong&gt;, then click &lt;strong&gt;Next&lt;/strong&gt; again.&lt;/p&gt; &lt;p&gt;Most tasks in this quick start are self-explanatory, but a couple of them are worth exploring.&lt;/p&gt; &lt;h3&gt;Task 3: View the associated Git repository&lt;/h3&gt; &lt;p&gt;The developer sandbox lets developers change application code directly using CodeReady Workspaces instead of navigating to the Git repository from a local IDE. This makes pre-configuring the application easier, as I mentioned earlier. You also can run the "getting started" application in Quarkus development mode, which lets you use Quarkus's live coding feature for continuous development.&lt;/p&gt; &lt;p&gt;When you click the &lt;strong&gt;CodeReady Workspaces&lt;/strong&gt; icon in the bottom-right quadrant of the &lt;strong&gt;quarkus-quickstarts&lt;/strong&gt; deployment, it brings you to CodeReady Workspaces, as shown in Figure 5.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="CodeReady Workspaces opens in the console." data-entity-type="file" data-entity-uuid="0b229b5c-9059-418f-8844-5af1a0bda0eb" height="317" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.27.16%20PM.png" width="569" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 5: View your code in CodeReady Workspaces.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Task 6: Run the Quarkus application&lt;/h3&gt; &lt;p&gt;In Task 6, you can access the Quarkus application's REST API. Click the external link icon to open the URL and run the application in a new browser tab, as shown in Figure 6.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Run the Quarkus application from the REST API." data-entity-type="file" data-entity-uuid="aefc7785-9e09-48bb-bffd-c263a105b841" height="311" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.28.12%20PM.png" width="570" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 6: Open the Quarkus application URL.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Step 5: Finish the quick start&lt;/h2&gt; &lt;p&gt;When you have completed all six tasks you will see the green checkmarks shown in Figure 7.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Each task has a green checkmark beside it." data-entity-type="file" data-entity-uuid="e9e9ae91-9c5e-497f-b6d5-2ca8d8c7b1f5" height="462" src="https://developers.redhat.com/sites/default/files/inline-images/Screen%20Shot%202021-05-24%20at%205.28.56%20PM_0.png" width="527" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 7: The green checkmarks indicate that all tasks have been completed.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Great job! Now, you can tour another quick start or repeat this one as a learning practice.&lt;/p&gt; &lt;h2&gt;Watch the Quarkus quick starts video demonstration&lt;/h2&gt; &lt;p&gt;If you want further instruction, this video demonstration guides you through two of the three available Quarkus quick starts: "Get started with Quarkus using S2I" and "Get started with Quarkus using a Helm chart."&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you've learned how much faster you can get started with Quarkus application development and deployment using Quarkus quick starts in the Developer Sandbox for Red Hat OpenShift. The sandbox is free for all business application developers who are interested in cloud-native microservices development using Quarkus. The sandbox lets you use a modern web-based IDE for development and deploy your cloud-native microservices applications to a Red Hat OpenShift cluster seamlessly. Use the self-service learning portal &lt;a href="https://developers.redhat.com/courses/quarkus"&gt;here&lt;/a&gt; to learn more about Java application development with Quarkus.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/31/learn-quarkus-faster-quick-starts-developer-sandbox-red-hat-openshift" title="Learn Quarkus faster with quick starts in the Developer Sandbox for Red Hat OpenShift"&gt;Learn Quarkus faster with quick starts in the Developer Sandbox for Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FSoQUzD7WPk" height="1" width="1" alt=""/&gt;</summary><dc:creator>Daniel Oh</dc:creator><dc:date>2021-05-31T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/31/learn-quarkus-faster-quick-starts-developer-sandbox-red-hat-openshift</feedburner:origLink></entry><entry><title type="html">This Week in JBoss - 31 May 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ApC_h-WHvGM/weekly-2021-05-31.html" /><category term="quarkus" /><category term="wildfly" /><category term="keycloak" /><category term="kogito" /><category term="infinispan" /><category term="camel" /><category term="jgroups" /><category term="vert.x" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2021-05-31.html</id><updated>2021-05-31T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, wildfly, keycloak, kogito, infinispan, camel, jgroups, vert.x"&gt; &lt;h1&gt;This Week in JBoss - 31 May 2021&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello! Welcome to another edition of the JBoss Editorial that brings you news and updates from our community.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_hello_again"&gt;Hello again&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;To our community and all our readers,&lt;/p&gt; &lt;p&gt;I’d like to start this edition with a sincere and frank apology on behalf of the editorial team for the posts we missed in the last month.&lt;/p&gt; &lt;p&gt;There’s been a lot of awesome content that our community has shared and multiple project releases packed with useful new features and clever enhancements. We’re long overdue in highlighting and celebrating all the great work that JBoss teams are doing, not to mention all the brilliant work of our evangelists and other contributors.&lt;/p&gt; &lt;p&gt;It’s been a busy past few weeks and we’ve got a lot of great articles and releases to catch up on, so let’s go.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Let’s start things off with congrats to all the teams on their hard work!&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://belaban.blogspot.com/2021/05/jgroups-517-released.html/"&gt;JGroups 5.1.7&lt;/a&gt; is released. Congrats, Bela!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-1-13-6-final-released/"&gt;Quarkus 1.13.6.Final&lt;/a&gt; has shipped, which is the latest in a recent series of updates to version 1.13.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-0-0-cr2-released/"&gt;Quarkus 2 CR2&lt;/a&gt; is out!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vertx.io/blog/eclipse-vert-x-4-1-CR2-released/"&gt;Vert.x 4.1.0.CR2&lt;/a&gt; is here, right on the heels of the beta and CR1 releases.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/blog/2021/05/07/infinispan-12-1-2-final"&gt;Infinispan 12.1.2 Final&lt;/a&gt; is available for download so go grab it.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2021/05/keycloak-1301-released"&gt;Keycloak 13.0.1&lt;/a&gt; is out!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2021/05/kogito-tooling-0-10-0-released.html"&gt;Kogito Tooling 0.10.0&lt;/a&gt; has launched!&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://bytemanblog.blogspot.com/2021/05/byteman-4015-has-been-released.html]"&gt;Byteman 4.0.15&lt;/a&gt; is now available!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_quarkus_2_ama"&gt;Quarkus 2 AMA&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;With the recent release of Quarkus CR2, I’m sure we’re all anticipating Quarkus 2.0 GA. As part of that release, Max and the rest of the Quarkus team are taking questions that they will answer on an episode of Quarkus Insights. Use the &lt;code&gt;#quarkusinsights&lt;/code&gt; tag to submit a question via social media and tune in to &lt;a href="https://www.youtube.com/watch?v=ETTMBWEBfLY"&gt;Quarkus Insights #51: Q &amp;#38; A - Part II&lt;/a&gt; on June 2 to hear your questions answered.&lt;/p&gt; &lt;p&gt;Follow the social media links to post your question to the Quarkus team in their post, &lt;a href="https://quarkus.io/blog/quarkus-insights-qanda2/"&gt;About to release Quarkus 2 - ask us anything!&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_from_the_community"&gt;From the community&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Jeff Mesnil has authored a very helpful and detailed look at building and deploying WildFly applications on OpenShift using Helm Charts in his post, &lt;a href="https://www.wildfly.org/news/2021/05/05/helm-charts-for-wildfly/"&gt;Helm Chart for WildFly&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Over on the Infinispan blog, Ryan Emerson has shared some details about the CLI compiled to a native image in &lt;a href="https://infinispan.org/blog/2021/05/21/infinispan-cli-image"&gt;Infinispan Native CLI&lt;/a&gt;, which is well worth a read. You should also try downloading the latest Infinispan 12 server version and taking it for a spin with the native CLI!&lt;/p&gt; &lt;p&gt;Another recent one from the Infinispan team comes from Katia Aresti who, along with Ryan Emerson, explains how they &lt;a href="https://developers.redhat.com/articles/2021/05/28/building-real-time-leaderboard-red-hat-data-grid-and-quarkus-hybrid-kubernetes"&gt;built a real-time leaderboard using Data Grid and several Quarkus extensions&lt;/a&gt; to add some magic to this year’s Red Hat Summit Keynote.&lt;/p&gt; &lt;p&gt;Jacopo Rota on the Kogito blog explains how to &lt;a href="https://blog.kie.org/2021/05/getting-started-with-trustyai-in-only-15-minutes.html"&gt;how to deploy a Kogito service together with the TrustyAI infrastructure on an OpenShift cluster in only 15 minutes&lt;/a&gt;!&lt;/p&gt; &lt;p&gt;Have you been wanting to find out more about Shenandoah GC? Well, you should dive right in and check out Roman Kennke’s informative post, &lt;a href="https://developers.redhat.com/articles/2021/05/20/shenandoah-garbage-collection-openjdk-16-concurrent-reference-processing"&gt;Shenandoah garbage collection in OpenJDK 16: Concurrent reference processing&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Bilgin Ibryam has recently posted &lt;a href="http://www.ofbizian.com/2021/05/data-gateways-of-future.html"&gt;Data Gateways in the Cloud Native Era&lt;/a&gt; that examines how data gateway components support different use cases and offer a solution for hybrid workloads spread across multiple cloud providers.&lt;/p&gt; &lt;p&gt;Last but certainly not least is Claus Ibsen’s webinar, &lt;a href="http://www.davsclaus.com/2021/05/webinar-integrate-systems-in-age-of.html"&gt;Integrate systems in the age of Quarkus and Camel&lt;/a&gt;, that explores how the trio of Camel Quarkus, Camel K, and Kamelets simplify the work to manage and bind systems together.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_evangelists_corner"&gt;Evangelist’s corner&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Eric Schabell never disappoints and his previous series on architectural elements in a real-time stock control solution for retail was no exception. Eric rounds that series off nicely with &lt;a href="https://www.schabell.org/2021/05/real-time-stock-control-example-stock-control-architecture.html"&gt;Real-time stock control - Example stock control architecture&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Not one to rest for long, Eric Schabell launches a new series that tackles how to create a framework for accessing retail data from customers, stock, stores, and staff across multiple internal teams. I’m sure it’s going to be a brilliant series so go have a look for yourself and find out more in his post, &lt;a href="https://www.schabell.org/2021/05/retail-data-framework-architectural-introduction.html"&gt;Retail data framework - An architectural introduction&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I also really enjoyed reading through Christina and Eric’s &lt;a href="http://wei-meilin.blogspot.com/2021/05/tooling-guide-for-getting-started-with.html"&gt;Tooling guide for Getting Started with Apache Camel in 2021&lt;/a&gt;. It’s a well put together beginner’s guide to tools that can help with Camel applications.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_developers_on_film"&gt;Developers on film&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Get your popcorn ready and sit back to watch some videos from our community. Here are my top picks for this week’s editorial:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/ILl85LLj93w"&gt;Quarkus Insights #49: Why I use Quarkus for Cloud Native Apps&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/7JPm1BFcrrk"&gt;What is Serverless with Java?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/jBDmX85IjLM"&gt;No YAML! Kubernetes done the easy way&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/szza3DZlKzA"&gt;Quarkus DevServices&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ApC_h-WHvGM" height="1" width="1" alt=""/&gt;</content><dc:creator>Don Naro</dc:creator><feedburner:origLink>https://www.jboss.org/posts/weekly-2021-05-31.html</feedburner:origLink></entry><entry><title type="html">Data Gateways in the Cloud Native Era</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/r9Na-7W7j-Y/data-gateways-of-future.html" /><author><name>Unknown</name></author><id>http://www.ofbizian.com/2021/05/data-gateways-of-future.html</id><updated>2021-05-29T11:52:00Z</updated><content type="html">These days, there is a lot of excitement around 12-factor apps, microservices, and service mesh, but not so much around cloud-native data. The number of conference talks, blog posts, best practices, and purpose-built tools around cloud-native data access is relatively low. One of the main reasons for this is because most data access technologies are architectured and created in a stack that favors static environments rather than the dynamic nature of cloud environments and Kubernetes. In this article, we will explore the different categories of data gateways, from more monolithic to ones designed for the cloud and Kubernetes. We will see what are the technical challenges introduced by the Microservices architecture and how data gateways can complement API gateways to address these challenges in the Kubernetes era. APPLICATION ARCHITECTURE EVOLUTIONS Let’s start with what has been changing in the way we manage code and the data in the past decade or so. I still remember the time when I started my IT career by creating frontends with Servlets, JSP, and JSFs. In the backend, EJBs, SOAP, server-side session management, was the state of art technologies and techniques. But things changed rather quickly with the introduction of REST and popularization of Javascript. REST helped us decouple frontends from backends through a uniform interface and resource-oriented requests. It popularized stateless services and enabled response caching, by moving all client session state to clients, and so forth. This new architecture was the answer to the huge scalability demands of modern businesses. A similar change happened with the backend services through the Microservices movement. Decoupling from the frontend was not enough, and the monolithic backend had to be decoupled into bounded context enabling independent fast-paced releases. These are examples of how architectures, tools, and techniques evolved pressured by the business needs for fast software delivery of planet-scale applications. That takes us to the data layer. One of the existential motivations for microservices is having independent data sources per service. If you have microservices touching the same data, that sooner or later introduces coupling and limits independent scalability or releasing. It is not only an independent database but also a heterogeneous one, so every microservice is free to use the database type that fits its needs. Application architecture evolution brings new challenges While decoupling frontend from backend and splitting monoliths into microservices gave the desired flexibility, it created challenges not-present before. Service discovery and load balancing, network-level resilience, and observability turned into major areas of technology innovation addressed in the years that followed. Similarly, creating a database per microservice, having the freedom and technology choice of different datastores is a challenge. That shows itself more and more recently with the explosion of data and the demand for accessing data not only by the services but other real-time reporting and AI/ML needs. THE RISE OF API GATEWAYS With the increasing adoption of Microservices, it became apparent that operating such an architecture is hard. While having every microservice independent sounds great, it requires tools and practices that we didn’t need and didn’t have before. This gave rise to more advanced release strategies such as blue/green deployments, canary releases, dark launches. Then that gave rise to fault injection and automatic recovery testing. And finally, that gave rise to advanced network telemetry and tracing. All of these created a whole new layer that sits between the frontend and the backend. This layer is occupied primarily with API management gateways, service discovery, and service mesh technologies, but also with tracing components, application load balancers, and all kinds of traffic management and monitoring proxies. This even includes projects such as Knative with activation and scaling-to-zero features driven by the networking activity. With time, it became apparent that creating microservices at a fast pace, operating microservices at scale requires tooling we didn’t need before. Something that was fully handled by a single load balancer had to be replaced with a new advanced management layer. A new technology layer, a new set of practices and techniques, and a new group of users responsible were born. THE CASE FOR DATA GATEWAYS Microservices influence the data layer in two dimensions. First, it demands an independent database per microservice. From a practical implementation point of view, this can be from an independent database instance to independent schemas and logical groupings of tables. The main rule here is, only one microservice owns and touches a dataset. And all data is accessed through the APIs or Events of the owning microservice. The second way a microservices architecture influenced the data layer is through datastore proliferation. Similarly, enabling microservices to be written in different languages, this architecture allows the freedom for every microservices-based system to have a  persistence layer. With this freedom, one microservice can use a relational database, another one can use a document database, and the third microservice one uses an in-memory key-value store. While microservices allow you all that freedom, again it comes at a cost. It turns out operating a large number of datastore comes at a cost that existing tooling and practices were not prepared for. In the modern digital world, storing data in a reliable form is not enough. Data is useful when it turns into insights and for that, it has to be accessible in a controlled form by many. AI/ML experts, data scientists, business analysts, all want to dig into the data, but the application-focused microservices and their data access patterns are not  for these data-hungry demands. API and Data gateways offering similar capabilities at different layers This is where data gateways can help you. A data gateway is like an API gateway, but it understands and acts on the physical data layer rather than the networking layer. Here are a few areas where data gateways differ from API gateways. ABSTRACTION An API gateway can hide implementation endpoints and help upgrade and rollback services without affecting service consumers. Similarly, a data gateway can help abstract a physical data source, its specifics, and help alter, migrate, decommission, without affecting data consumers. SECURITY An API manager secures resource endpoints based on HTTP methods. A service mesh secures based on network connections. But none of them can understand and secure the data and its shape that is passing through them. A data gateway, on the other hand, understands the different data sources and the data model and acts on them. It can apply RBAC per data row and column, filter, obfuscate, and sanitize the individual data elements whenever necessary. This is a more fine-grained security model than networking or API level security of API gateways. SCALING API gateways can do service discovery, load-balancing, and assist the scaling of services through an orchestrator such as Kubernetes. But they cannot scale data. Data can scale only through replication and caching. Some data stores can do replication in cloud-native environments but not all. Purpose-built tools, such as , can perform change data capture from the transaction logs of data stores and enable data replication for scaling and other use cases. A data gateway, on the other hand, can speed-up access to all kinds of data sources by caching data and providing materialized views. It can understand the queries, optimize them based on the capabilities of the data source, and produce the most performant execution plan. The combination of materialized views and the stream nature of change data capture would be the ultimate data scaling technique, but there are no known cloud-native implementations of this yet. FEDERATION In API management, response composition is a common technique for aggregating data from multiple different systems. In the data space, the same technique is referred to as heterogeneous data federation. Heterogeneity is the degree of differentiation in various data sources such as network protocols, query languages, query capabilities, data models, error handling, transaction semantics, etc. A data gateway can accommodate all of these differences as a seamless, transparent data-federation layer. SCHEMA-FIRST API gateways allow contract-first service and client development with specifications such as OpenAPI. Data gateways allow schema-first data consumption based on the SQL standard. A SQL schema for data modeling is the OpenAPI equivalent of APIs. MANY SHADES OF DATA GATEWAYS In this article, I use the terms API and data gateways loosely to refer to a set of capabilities. There are many types of API gateways such as API managers, load balancers, service mesh, service registry, etc. It is similar to data gateways, where they range from huge monolithic data virtualization platforms that want to do everything, to data federation libraries, from purpose-built cloud services to end-user query tools. Let’s explore the different types of data gateways and see which fit the definition of “a cloud-native data gateway.” When I say a cloud-native data gateway, I mean a containerized first-class Kubernetes citizen. I mean a gateway that is open source, using open standards; a component that can be deployed on hybrid/multi-cloud infrastructures, work with different data sources, data formats, and applicable for many use cases. CLASSIC DATA VIRTUALIZATION PLATFORMS In the very first category of data gateways, are the traditional data virtualization platforms such as  and . While these are the most feature-laden data platforms, they tend to do too much and want to be everything from API management, to metadata management, data cataloging, environment management, deployment, configuration management, and whatnot. From an architectural point of view, they are very much like the old ESBs, but for the data layer. You may manage to put them into a container, but it is hard to put them into the cloud-native citizen category. DATABASES WITH DATA FEDERATION CAPABILITIES Another emerging trend is the fact that databases, in addition to storing data, are also starting to act as data federation gateways and allowing access to external data. For example, PostgreSQL  the ANSI SQL/MED specification for a standardized way of handling access to remote objects from SQL databases. That means remote data stores, such as SQL, NoSQL, File, LDAP, Web, Big Data, can all be accessed as if they were tables in the same PostgreSQL database. SQL/MED stands for Management of External Data, and it is also implemented by MariaDB  engine, , Teiid project discussed below, and a few . Starting in SQL Server 2019, you can now query external data sources without moving or copying the data. The  engine of SQL Server instance to process Transact-SQL queries to access external data in SQL Server, Oracle, Teradata, and MongoDB. GRAPHQL DATA BRIDGES Compared to the traditional data virtualization, this is a new category of data gateways focused around the fast web-based data access. The common thing around , , , is that they focus on GraphQL data access by offering a lightweight abstraction on top of a few data sources. This is a fast-growing category specialized for enabling rapid web-based development of data-driven applications rather than BI/AI/ML use cases. OPEN-SOURCE DATA GATEWAYS  is a schema-free SQL query engine for NoSQL databases and file systems. It offers JDBC and ODBC access to business users, analysts, and data scientists on top of data sources that don’t support such APIs. Again, having uniform SQL based access to disparate data sources is the driver. While Drill is highly scalable, it relies on Hadoop or Apache Zookeeper’s kind of infrastructure which shows its age.  is a mature data federation engine sponsored by Red Hat. It uses the SQL/MED specification for defining the virtual data models and relies on the Kubernetes Operator model for the building, deployment, and management of its runtime. Once deployed, the runtime can scale as any other stateless cloud-native workload on Kubernetes and integrate with other cloud-native projects. For example, it can use  for single sign-on and data roles,  for distributed caching needs, export metrics and register with Prometheus for monitoring, Jaeger for tracing, and even with for API management. But ultimately, Teiid runs as a single Spring Boot application acting as a data proxy and integrating with other best-of-breed services on Openshift rather than trying to reinvent everything from scratch. Architectural overview of Teiid data gateway On the client-side, Teiid offers standard SQL over JDBC/ODBC and Odata APIs. Business users, analysts, and data scientists can use standard BI/analytics tools such as Tableau, MicroStrategy, Spotfire, etc. to interact with Teiid. Developers can leverage the REST API or JDBC for custom built microservices and serverless workloads. In either case, for data consumers, Teiid appears as a standard PostgreSQL database accessed over its JDBC or ODBC protocols but offering additional abstractions and decoupling from the physical data sources.  is another popular open-source project started by Facebook. It is a distributed SQL query engine targeting big data use cases through its coordinator-worker architecture. The Coordinator is responsible for parsing statements, planning queries, managing workers, fetching results from the workers, and returning the final results to the client. The worker is responsible for executing tasks and processing data.  Some time ago, the founders split from PrestoDB and created a fork called (formerly PrestoSQL). Today, PrestoDB is part of The Linux Foundation, and Trino part of Trino Software Foundation. Both distributions of Presto are among the most active and powerful open-source data gateway projects in this space. To learn more about this technology, is a good book I found. CLOUD-HOSTED DATA GATEWAYS SERVICES With a move to the cloud infrastructure, the need for data gateways doesn’t go away but increases instead. Here are a few cloud-based data gateway services:  is ANSI SQL based interactive query service for analyzing data tightly integrated with Amazon S3. It is based on PrestoDB and supports additional data sources and federation capabilities too. Another similar service by Amazon is . It is focused around the same functionality, i.e. querying S3 objects using SQL. The main difference is that Redshift Spectrum requires a Redshift cluster, whereas Athena is a serverless offering that doesn’t require any servers.  is a similar service but from Google. These tools require minimal to no setup, they can access on-premise or cloud-hosted data and process huge datasets. But they couple you with a single cloud provider as they cannot be deployed on multiple clouds or on-premise. They are ideal for interactive querying rather than acting as hybrid data frontend for other services and tools to use. SECURE TUNNELING DATA-PROXIES With cloud-hosted data gateways comes the need for accessing on-premise data. Data has gravity and also might be affected by regulatory requirements preventing it from moving to the cloud. It may also be a conscious decision to keep the most valuable asset (your data) from cloud-coupling. All of these cases require cloud access to on-premise data. And cloud providers make it easy to reach your data. Azure’s  is such a proxy allowing access to on-premise data stores from Azure Service Bus. In the opposite scenario, accessing cloud-hosted data stores from on-premise clients can be challenging too. Google’s  provides secure access to Cloud SQL instances without having to whitelist IP addresses or configure SSL. Red Hat-sponsored open-source project  takes the more generic approach to address these challenges. Skupper solves Kubernetes multi-cluster communication challenges through a layer 7 virtual network that offers advanced routing and secure connectivity capabilities. Rather than embedding Skupper into the business service runtime, it runs as a standalone instance per Kubernetes namespace and acts as a shared sidecar capable of secure tunneling for data access or other general service-to-service communication. It is a generic secure-connectivity proxy applicable for many use cases in the hybrid cloud world. CONNECTION POOLS FOR SERVERLESS WORKLOADS Serverless takes software decomposition a step further from microservices. Rather than services splitting by bounded context, serverless is based on the function model where every operation is short-lived and performs a single operation. These granular software constructs are extremely scalable and flexible but come at a cost that previously wasn’t present. It turns out rapid scaling of functions is a challenge for connection-oriented data sources such as relational databases and message brokers. As a result cloud providers offer transparent data proxies as a service to manage connection pools effectively.  is such a service that sits between your application and your relational database to efficiently manage connections to the database and improve scalability. CONCLUSION Modern cloud-native architectures combined with the microservices principles enable the creation of highly scalable and independent applications. The large choice of data storage engines, cloud-hosted services, protocols, and data formats, gives the ultimate flexibility for delivering software at a fast pace. But all of that comes at a cost that becomes increasingly visible with the need for uniform real-time data access from emerging user groups with different needs. Keeping microservices data only for the microservice itself creates challenges that have no good technological and architectural answers yet. Data gateways, combined with cloud-native technologies offer features similar to API gateways but for the data layer that can help address these new challenges. The data gateways vary in specialization, but they tend to consolidate on providing uniform SQL-based access, enhanced security with data roles, caching, and abstraction over physical data stores. Data has gravity, requires granular access control, is hard to scale, and difficult to move on/off/between cloud-native infrastructures. Having a data gateway component as part of the cloud-native tooling arsenal, which is hybrid and works on multiple cloud providers, supports different use cases is becoming a necessity. This article was originally published on InfoQ .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/r9Na-7W7j-Y" height="1" width="1" alt=""/&gt;</content><dc:creator>Unknown</dc:creator><feedburner:origLink>http://www.ofbizian.com/2021/05/data-gateways-of-future.html</feedburner:origLink></entry><entry><title type="html">Webinar: Integrate systems in the age of Quarkus and Camel</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/g-Owy-ABX_4/webinar-integrate-systems-in-age-of.html" /><author><name>Claus Ibsen</name></author><id>http://feedproxy.google.com/~r/ApacheCamel/~3/BkZSRxVBBG4/webinar-integrate-systems-in-age-of.html</id><updated>2021-05-29T09:15:00Z</updated><content type="html">A few days ago I presented a webinar where he covered all the latest innovations with Apache Camel with focus on Camel Quarkus, Camel K, and Kamelets. This trio is a powerful combination that takes Camel to another level, which allows non developers and IT professionals, to manage and bind systems together without any Camel knowledge. Kamelets being the Apache Camel solution for an app store experience with integration software. The webinar is and the .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/g-Owy-ABX_4" height="1" width="1" alt=""/&gt;</content><dc:creator>Claus Ibsen</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/BkZSRxVBBG4/webinar-integrate-systems-in-age-of.html</feedburner:origLink></entry><entry><title>How to install Kubeflow 1.2 on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Lvgqj4tFZM4/how-install-kubeflow-12-red-hat-openshift" /><author><name>David Marcus</name></author><id>78521b1a-011c-4ff6-b07a-3c5e1142b49e</id><updated>2021-05-28T07:00:00Z</updated><published>2021-05-28T07:00:00Z</published><summary type="html">&lt;p&gt;As artificial intelligence (AI) adoption increases across industries, particularly through machine learning (ML), the job of integrating the often disparate tools, libraries, packages, and dependencies also increases in complexity. This makes development and operations (&lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt;) a daunting task that both organizations and open source communities are actively working on. To quote the authors of &lt;a href="https://web.kaust.edu.sa/Faculty/MarcoCanini/classes/CS290E/F19/papers/tech-debt.pdf"&gt;Hidden Technical Debt in Machine Learning Systems&lt;/a&gt;, "developing and deploying ML systems is relatively fast and cheap, but maintaining them over time is difficult and expensive."&lt;/p&gt; &lt;p&gt;If you are in the throes of tackling DevOps for &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;AI/ML&lt;/a&gt; (MLOps), two open source projects worth your attention are the upstream &lt;a href="https://www.kubeflow.org/"&gt;Kubeflow&lt;/a&gt; and the downstream &lt;a href="https://opendatahub.io/"&gt;Open Data Hub&lt;/a&gt; (ODH). The goal of these projects is to provide machine learning toolkits that handle the complex parts of orchestration that traditional software DevOps does not.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: For more about MLOps, see, &lt;a href="https://www.openshift.com/blog/dotscience-on-openshift"&gt;Dotscience on OpenShift: Enabling DevOps for MLOps&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As the name indicates, Kubeflow is based on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. In this article, we'll show it running on &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; and include an &lt;a href="https://developers.redhat.com/topics/service-mesh"&gt;Istio service mesh&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Objective&lt;/h2&gt; &lt;p&gt;Use this article as a startup procedure to install a default Kubeflow toolkit on an OpenShift Container Platform instance to explore the tools and capabilities. Figure 1 shows the Kubeflow dashboard running on OpenShift Container Platform, providing access to a suite of machine learning tools that span the system life cycle.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-ui.png?itok=G5FBZdI9" width="600" height="444" alt="Screenshot of the kubeflow central dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Kubeflow central dashboard. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Kubeflow central dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The latest release of Kubeflow at the time of this writing incorporates changes to the file structure for distribution-specific platforms, such as OpenShift. If you are interested in the details, you can read the source &lt;a href="https://github.com/kubeflow/manifests/pull/1739"&gt;pull request&lt;/a&gt; that explains the reason for the change.&lt;/p&gt; &lt;h3&gt;Overview of major steps&lt;/h3&gt; &lt;p&gt;The following list summarizes the steps needed to get Kubeflow running on OpenShift Container Platform:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Install the Open Data Hub Operator.&lt;/li&gt; &lt;li&gt;Create the Kubeflow project.&lt;/li&gt; &lt;li&gt;Install Kubeflow.&lt;/li&gt; &lt;li&gt;Monitor the installation.&lt;/li&gt; &lt;li&gt;Access the Kubeflow user interface (UI).&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;Requirements&lt;/h3&gt; &lt;p&gt;To use Kubeflow as shown in this article, please note the following requirements:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;You &lt;em&gt;must&lt;/em&gt; have an OpenShift Container Platform cluster 4.2+ installed with cluster admin privileges.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;should not&lt;/em&gt; have an &lt;a href="https://istio.io/latest/docs/ops/deployment/deployment-models/#multiple-meshes"&gt;existing Istio service mesh&lt;/a&gt;, because it will lead to name collisions.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;should not&lt;/em&gt;have an existing project named &lt;code&gt;istio-system&lt;/code&gt; as &lt;a href="https://www.kubeflow.org/docs/external-add-ons/istio/istio-in-kubeflow/"&gt;Kubeflow deploys Istio along with configurations&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;must not&lt;/em&gt; have remaining mutating webhooks or validating webhooks from prior tests.&lt;/li&gt; &lt;li&gt; &lt;p&gt;You &lt;em&gt;must not&lt;/em&gt; deploy Kubeflow in a project or namespace other than &lt;code&gt;kubeflow&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Running on an OpenShift cluster&lt;/h2&gt; &lt;p&gt;Here are some options for getting access to an OpenShift cluster to run through the procedure in this article. Getting a cluster running is beyond the scope of the tutorial, but the resources in this section offer a starting point.&lt;/p&gt; &lt;h3&gt;On your local machine cluster (recommended)&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; is designed to run on a local computer to simplify setup and testing. The product emulates the cloud development environment with all of the tools needed to develop container-based applications.&lt;/p&gt; &lt;h3&gt;On a 60-minute temporary cluster (only for learning)&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.katacoda.com/openshift/courses/playgrounds/"&gt;Katacoda&lt;/a&gt; offers an OpenShift cluster as a playground that can be used to perform this installation, as long as you complete the task in an hour or less. It can be done.&lt;/p&gt; &lt;h3&gt;More options&lt;/h3&gt; &lt;p&gt;See the &lt;a href="https://www.openshift.com/try"&gt;OpenShift trial page&lt;/a&gt; for other options.&lt;/p&gt; &lt;h2&gt;Installing the Open Data Hub Operator&lt;/h2&gt; &lt;p&gt;Kubeflow should be installed on OpenShift using the Open Data Hub Operator from the &lt;a href="https://catalog.redhat.com/software/operators/explore"&gt;OpenShift Operators catalog&lt;/a&gt;. The upstream Kubeflow Operator from &lt;a href="http://operatorhub.io"&gt;OperatorHub.io&lt;/a&gt; will not run successfully on OpenShift because it is intended for a general-purpose Kubernetes cluster.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Operators&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;OperatorHub&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Search for "Open Data Hub."&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub Operator&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Continue&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Accept the default installation strategy, which uses the following settings: &lt;ul&gt;&lt;li&gt;Update Channel: beta&lt;/li&gt; &lt;li&gt;Installation mode: All namespaces on the cluster (default)&lt;/li&gt; &lt;li&gt;Installed Namespace: &lt;code&gt;openshift-operators&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Approval strategy: Automatic&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 2 illustrates the Open Data Hub Operator selection from the OpenShift OperatorHub.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-install.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-install.png?itok=piT5UOJ3" width="600" height="307" alt="Screenshot of Open Data Hub Operator install from the Red Hat OpenShift OperatorHub" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Open Data Hub Operator install. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Open Data Hub Operator installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating the Kubeflow project&lt;/h2&gt; &lt;p&gt;Kubeflow must be installed in a namespace called &lt;code&gt;kubeflow&lt;/code&gt;. A request for an alternative namespace is an &lt;a href="https://github.com/kubeflow/kubeflow/issues/5647"&gt;open issue&lt;/a&gt; at the time of this writing.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Home&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Projects&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create Project&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Set the following values: &lt;ul&gt;&lt;li&gt;Name: &lt;code&gt;kubeflow&lt;/code&gt; (cannot be altered)&lt;/li&gt; &lt;li&gt;Display Name: &lt;code&gt;kubeflow&lt;/code&gt; (unlike the previous name, you can choose another value here)&lt;/li&gt; &lt;li&gt;Description: Kubeflow ML toolkit (you can choose another value)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Change to the &lt;code&gt;kubeflow&lt;/code&gt; project.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Operators—&gt;Installed Operators&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Wait for the Operator to display "Succeeded" in the Status field.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 3 displays the expected result when the operator is completely installed.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-succeeded.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-succeeded.png?itok=Hovsw1gE" width="600" height="191" alt="Screenshot of Open Data Hub Operator with a succeeded status" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: ODH Operator successful installation. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: A succesful installation of the Open Data Hub Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Installing Kubeflow&lt;/h2&gt; &lt;p&gt;By default, the Open Data Hub Operator includes a manifest that lets you try out different components for MLOps. Because the toolset used in this article is different from the one in the default manifest, you should paste in a different manifest.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Click the &lt;strong&gt;Open Data Hub Operator&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; link under &lt;strong&gt;Provided APIs&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create KfDef&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;YAML View&lt;/strong&gt; radio button.&lt;/li&gt; &lt;li&gt;Delete all the YAML code.&lt;/li&gt; &lt;li&gt;Copy and paste in all the YAML code from &lt;a href="https://raw.githubusercontent.com/kubeflow/manifests/master/distributions/kfdef/kfctl_openshift.v1.2.0.yaml"&gt;kfctl_openshift.v1.2.0.yaml&lt;/a&gt;. &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For reference, the HTML version can be found on &lt;a href="https://github.com/kubeflow/manifests/tree/master/distributions/kfdef"&gt;Kubeflow GitHub manifests&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 4 shows the Provided APIs selection.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-api.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-api.png?itok=V9y8Mcio" width="600" height="190" alt="Screenshot of the provided API for selection to create a KfDef and edit YAML" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Open Data Hub Provide API. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Open Data Hub Provided APIs.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 5 shows the YAML code you will replace.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kfctl-yaml.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kfctl-yaml.png?itok=nEXuGo9_" width="600" height="444" alt="Screenshot of the YAML View to replace existing YAML with provided YAML for Kubeflow" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: ODH Provided API KfDef YAML View. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Open Data Hub Provided API KfDef YAML View.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Monitoring the installation&lt;/h2&gt; &lt;p&gt;In the background, the Open Data Hub Operator performs the commands a system administrator would execute on the command line to install Kubeflow, such as &lt;code&gt;kfctl build -f...&lt;/code&gt; and &lt;code&gt;kfctl apply -f...&lt;/code&gt; The web console doesn't show when the installation is complete, so this section shows a few ways to monitor the installation. If all the pods are running without errors, the installation is complete.&lt;/p&gt; &lt;h3&gt;Monitoring from the administrator perspective&lt;/h3&gt; &lt;p&gt;Streaming events are a great way to get a sense of what major activity is occurring after an action such as a deployment. To view the events:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Home&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Section the project: either &lt;code&gt;kubeflow&lt;/code&gt; to see just events for Kubeflow, or "All projects" to see the multiple projects being updated during installation.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Events&lt;/strong&gt; to monitor the deployment events stream.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 6 shows the events streaming during an installation in the &lt;code&gt;kubeflow&lt;/code&gt; project.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/events.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/events.png?itok=oi84DHiL" width="600" height="289" alt="Screenshot of the event stream during a new kubeflow installation" title="Project kubeflow event stream" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Event stream during installation &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Event stream during installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Workload status and alerts are a quick way to understand how progress is going. To view the workloads:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Projects&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;code&gt;kubeflow&lt;/code&gt; project link.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Workloads&lt;/strong&gt; menu item in the body of the screen to review pods.&lt;/li&gt; &lt;li&gt;Investigate workloads that don't self-correct (give them time to auto-correct).&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 7 shows workloads from the project overview page. Workloads in the project are also viewable from the vertical menu.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/overview.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/overview.png?itok=OE9glwyg" width="600" height="444" alt="Screenshot of the workloads from the project overview page" title="Kubeflow Workload Overview" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Kubeflow project Workloads overview &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Overview of the Kubeflow project workloads.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A project called &lt;code&gt;cert-manager&lt;/code&gt; gets created during installation. Its events and pods provide good insight. To view these events or pods:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: cert-manager&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Events&lt;/strong&gt; to review events. Under &lt;strong&gt;Workloads&lt;/strong&gt;, click &lt;strong&gt;Pods&lt;/strong&gt; to review pods.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 8 shows the pods for &lt;code&gt;cert-manager&lt;/code&gt;.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/cert-manager.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/cert-manager.png?itok=8DCGiju1" width="600" height="213" alt="Screenshot of the pods in the cert-manager project that gets created" title="Cert-manager project pods" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Project cert-manager pods status &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: Status of pods in the cert-manager pods status.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Another important project, &lt;code&gt;istio-system&lt;/code&gt;, is created during installation. This project hosts the Istio service mesh that handles all the networking between the services. To view the project:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Events&lt;/strong&gt; to review events. Under &lt;strong&gt;Workloads&lt;/strong&gt;, click &lt;strong&gt;Pods&lt;/strong&gt; to review pods. Under &lt;strong&gt;Networking&lt;/strong&gt;, click &lt;strong&gt;Routes&lt;/strong&gt; to access the URL to the Kubeflow central dashboard.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 9 shows the routes in the project.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/istio-route.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/istio-route.png?itok=PFfmkJTw" width="600" height="323" alt="Screenshot of the istio ingress gateway route to access kubeflow interface" title="Project istio-system routes" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Istio-system route for istio-ingressgateway &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: istio-system route for the istio-ingress gateway.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Monitoring from the developer perspective&lt;/h3&gt; &lt;p&gt;In addition to the administrator perspective, a developer perspective abstracts infrastructure features out of view to leave an uncluttered developer experience. To see this perspective:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to the &lt;strong&gt;developer&lt;/strong&gt; perspective.&lt;/li&gt; &lt;li&gt;Select &lt;strong&gt;Project: kubeflow&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Topology&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 10 shows the results.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kfctl-topology.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kfctl-topology.png?itok=fLwITOUL" width="600" height="426" alt="Screenshot of the app topology created in the kubeflow project" title="Developer Perspective Topology View" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: Developer Perspective kubeflow project topology &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: Kubeflow project topology in the developer perspective.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If there are no errors across the projects and the Kubeflow UI launches, the installation has succeeded.&lt;/p&gt; &lt;h2&gt;Accessing the Kubeflow UI&lt;/h2&gt; &lt;p&gt;This section offers two ways to access the Kubeflow central dashboard from the web console. For reference, a command-line query would look like:&lt;/p&gt; &lt;pre&gt; # oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}/' &lt;/pre&gt; &lt;h3&gt;Going to the dashboard from the administrator perspective&lt;/h3&gt; &lt;p&gt;From the administrator perspective, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Networking&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Routes&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the location URL &lt;code&gt;http://istio-ingressgateway...&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 11 shows how to find the location URL.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-dashboard.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-dashboard.png?itok=xGlofgx1" width="600" height="224" alt="Screenshot of the kubeflow dashboard route in the istio-system project" title="Route to Kubeflow Dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: Route to Kubeflow Dashboard in the istio-system project &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11: Route to the Kubeflow dashboard in the istio-system project.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Going to the dashboard from the developer perspective&lt;/h3&gt; &lt;p&gt;From the developer perspective, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Topology&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Search for "istio-ingressgateway."&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open URL&lt;/strong&gt; arrow icon, or click the &lt;code&gt;istio-ingressgateway&lt;/code&gt; pod and the URL under &lt;strong&gt;Resources—&gt;Routes&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 12 shows the location of the URL.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-route.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-route.png?itok=8JfpGtYM" width="600" height="416" alt="Screenshot of the app topology of the istio-system project to access Kubeflow dashboard" title="Kubeflow Topology Route" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: Developer Perspective route to Kubeflow from istio-system project &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: Developer perspective route to Kubeflow from istio-system project.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Viewing the Kubeflow central dashboard&lt;/h3&gt; &lt;p&gt;Once you complete the registration process and create a namespace, you will see a dashboard like the one in Figure 13.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-ui.png?itok=G5FBZdI9" width="600" height="444" alt="Screenshot of the kubeflow central dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Kubeflow central dashboard. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 13: The Kubeflow central dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Uninstalling Kubeflow&lt;/h2&gt; &lt;p&gt;No proper installation procedure is truly complete without an uninstallation procedure.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project kubeflow&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; Operator.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; link under &lt;strong&gt;Provided APIs&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Kebab&lt;/strong&gt; button (the one with three vertical dots) for your &lt;code&gt;kubeflow&lt;/code&gt; instance.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Delete KfDef&lt;/strong&gt; to begin the delete process for your &lt;code&gt;kubeflow&lt;/code&gt; instance.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;The procedure in this article illustrates a best practice you can follow to install Kubeflow on Red Hat OpenShift using the Open Data Hub Operator. The manifest file used provides an example toolkit from the Kubeflow project that you can fork, modify, and update to fit your production MLOps needs. Furthermore, the &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operator framework&lt;/a&gt; simplifies installation, operations, and maintenance as the community &lt;a href="https://opendatahub.io/docs/roadmap/future.html"&gt;continues to publish enhancements&lt;/a&gt; to both the operator and machine learning tooling in conjunction with the overall &lt;a href="https://www.openshift.com/learn/topics/ai-ml"&gt;benefits of AI/ML on Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/28/how-install-kubeflow-12-red-hat-openshift" title="How to install Kubeflow 1.2 on Red Hat OpenShift"&gt;How to install Kubeflow 1.2 on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Lvgqj4tFZM4" height="1" width="1" alt=""/&gt;</summary><dc:creator>David Marcus</dc:creator><dc:date>2021-05-28T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/28/how-install-kubeflow-12-red-hat-openshift</feedburner:origLink></entry></feed>
